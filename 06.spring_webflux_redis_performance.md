# Secci√≥n 06: Spring WebFlux & Redis: Performance

---

## Configuraci√≥n de proyecto

En esta secci√≥n vamos a comprobar el rendimiento de nuestra aplicaci√≥n usando Redis.

Primero realizaremos nuestra aplicaci√≥n sin redis, simplemente interactuando con nuestra base de datos, al finalizar
realizaremos una prueba de rendimiento usando `JMeter` (herramienta para pruebas de rendimiento).

![01.png](assets/section-06/01.png)

Segundo, a√±adiremos Redis a nuestra arquitectura y volveremos a ejecutar exactamente la misma prueba de rendimiento
para luego comparar resultados.

![02.png](assets/section-06/02.png)

## [Dependencias](https://start.spring.io/#!type=maven-project&language=java&platformVersion=3.5.4&packaging=jar&jvmVersion=21&groupId=dev.magadiflo&artifactId=redis-performance&name=redis-performance&description=Demo%20project%20for%20Spring%20Boot&packageName=dev.magadiflo.performance.app&dependencies=webflux,data-r2dbc,lombok,postgresql)

Vamos a crear un nuevo proyecto llamado `redis-performance`
desde [Spring Initializr](https://start.spring.io/#!type=maven-project&language=java&platformVersion=3.5.4&packaging=jar&jvmVersion=21&groupId=dev.magadiflo&artifactId=redis-performance&name=redis-performance&description=Demo%20project%20for%20Spring%20Boot&packageName=dev.magadiflo.performance.app&dependencies=webflux,data-r2dbc,lombok,postgresql)
cuyas dependencias ser√°n las siguientes.

````xml
<!--Spring Boot 3.5.4-->
<!--Java 21-->
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-r2dbc</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-webflux</artifactId>
    </dependency>

    <dependency>
        <groupId>org.postgresql</groupId>
        <artifactId>postgresql</artifactId>
        <scope>runtime</scope>
    </dependency>
    <dependency>
        <groupId>org.postgresql</groupId>
        <artifactId>r2dbc-postgresql</artifactId>
        <scope>runtime</scope>
    </dependency>
    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
        <optional>true</optional>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-test</artifactId>
        <scope>test</scope>
    </dependency>
    <dependency>
        <groupId>io.projectreactor</groupId>
        <artifactId>reactor-test</artifactId>
        <scope>test</scope>
    </dependency>
</dependencies>
````

## üß© Servicio de Producto - Versi√≥n 1 (Sin Redis)

En esta lecci√≥n desarrollamos una primera versi√≥n simple de nuestra aplicaci√≥n `WebFlux`. Esta versi√≥n no incluye
`Redis` ni otras optimizaciones. El objetivo es comprobar el rendimiento de la aplicaci√≥n interactuando √∫nicamente con
la base de datos relacional.

üëâ Esta implementaci√≥n inicial servir√° como `l√≠nea base` para comparar posteriormente el impacto del uso de `Redis`
como `cach√©`.

### üéØ Alcance

Esta versi√≥n se centra en la funcionalidad principal, por lo tanto:

- No se usan DTOs.
- No se aplica validaci√≥n.
- No se maneja cacheo.
- La estructura se limita a: `entidad + repositorio + servicio + controlador`.

### üß± Entidad: Product

Creamos una clase entidad que se mapea a la tabla `products` en la base de datos.

````java

@AllArgsConstructor
@NoArgsConstructor
@Builder
@Data
@Table(name = "products")
public class Product {
    @Id
    private Integer id;
    private String description;
    private double price;
}
````

üîé Notas:

- Se usa `@Builder` para facilitar la creaci√≥n de objetos `Product`.
- El campo id es la clave primaria (`@Id`).
- Las dem√°s propiedades (description, price) corresponden a columnas simples.

### üß© Repositorio Reactivo

Creamos un repositorio extendiendo `ReactiveCrudRepository`, el cual nos ofrece operaciones reactivas est√°ndar como
`findById(...)`, `save(...)`, `delete(...)`, entre otras.

````java
public interface ProductRepository extends ReactiveCrudRepository<Product, Integer> {
}
````

### üß∞ Servicio de producto

Para aplicar el `principio de Inversi√≥n de Dependencias`, definimos una interfaz de servicio que encapsula las
operaciones relacionadas al producto.

````java
public interface ProductService {
    Mono<Product> getProduct(Integer productId);

    Mono<Product> updateProduct(Integer productId, Product product);
}
````

A continuaci√≥n, implementamos esta interfaz en una clase concreta, que orquesta las operaciones del repositorio.

````java

@Slf4j
@RequiredArgsConstructor
@Service
public class ProductServiceImpl implements ProductService {

    private final ProductRepository productRepository;

    @Override
    @Transactional(readOnly = true)
    public Mono<Product> getProduct(Integer productId) {
        return this.productRepository.findById(productId);
    }

    @Override
    @Transactional
    public Mono<Product> updateProduct(Integer productId, Product product) {
        return this.productRepository.findById(productId)
                .map(productDB -> {
                    product.setId(productId);
                    return product;
                })
                .flatMap(this.productRepository::save)
                .switchIfEmpty(Mono.error(() -> new NoSuchElementException("No existe el producto con id: " + productId)));
    }
}
````

üîé Notas:

- Se usa `@Transactional` para asegurar la integridad transaccional.
- El m√©todo `updateProduct(...)`:
    - `findById(...)`: verifica que el producto exista.
    - `map(...)`: toma los nuevos datos (`product`), les asigna el ID del path (ignorando el que venga del body).
    - `flatMap(save)`: guarda el nuevo objeto con los datos actualizados.
    - `switchIfEmpty(...)`: maneja el caso en que no se encontr√≥ el producto.

### üåê Controlador Reactivo

Finalmente, exponemos los endpoints a trav√©s de un controlador `WebFlux`.

````java

@RequiredArgsConstructor
@RestController
@RequestMapping(path = "/api/v1/products")
public class ProductController {

    private final ProductService productService;

    @GetMapping(path = "/{productId}")
    public Mono<ResponseEntity<Product>> getProduct(@PathVariable Integer productId) {
        return this.productService.getProduct(productId)
                .map(ResponseEntity::ok);
    }

    @PutMapping(path = "/{productId}")
    public Mono<ResponseEntity<Product>> updateProduct(@PathVariable Integer productId,
                                                       @RequestBody Mono<Product> productMono) {
        return productMono
                .flatMap(product -> this.productService.updateProduct(productId, product))
                .map(ResponseEntity::ok);
    }
}
````

üîé Notas:

- Se utiliza `Mono<Product>` en el cuerpo de la petici√≥n para aprovechar el manejo reactivo de datos en flujo.
- `ResponseEntity` encapsula el resultado con su respectivo c√≥digo `HTTP (200 OK)`.
- No se maneja validaci√≥n ni errores a nivel del controlador en esta versi√≥n.

## üêò Postgres con Docker Compose

Para ejecutar nuestra base de datos `PostgreSQL` de forma r√°pida y aislada, utilizaremos `Docker Compose`. A
continuaci√≥n, definimos un contenedor para `Postgres` dentro del archivo `compose.yml`:

````yml
services:
  s-postgres:
    image: postgres:17-alpine
    container_name: c-postgres
    restart: unless-stopped
    ports:
      - '5433:5432'
    environment:
      POSTGRES_DB: db_redis_performance
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: magadiflo
    volumes:
      - postgres-data:/var/lib/postgresql/data

volumes:
  postgres-data:
    name: postgres-data
````

‚úÖ Esta base de datos se utilizar√° para almacenar los productos que consultaremos desde la aplicaci√≥n `WebFlux`.
Una vez creado el contenedor, podremos conectarnos a la base de datos desde nuestra aplicaci√≥n `Spring` usando el
puerto `5433`.

> üëâ Antes de eso, ser√° necesario agregar la configuraci√≥n de conexi√≥n correspondiente en el archivo `application.yml`
> de Spring Boot.

## üöÄ Levantando el contenedor de PostgreSQL

Antes de iniciar el contenedor de `PostgreSQL`, listamos los contenedores existentes en ejecuci√≥n para verificar
el estado actual del entorno.

````bash
$ docker container ls -a
CONTAINER ID   IMAGE                                 COMMAND                  CREATED       STATUS                        PORTS                                         NAMES
34818d6d187b   redis:8.0.3-alpine                    "docker-entrypoint.s‚Ä¶"   2 weeks ago   Up 21 minutes                 0.0.0.0:6379->6379/tcp, [::]:6379->6379/tcp   c-redis
````

Ahora s√≠, ejecutamos nuestro archivo `compose.yml` con `Docker Compose` para levantar el contenedor de `PostgreSQL`.

````bash
D:\programming\spring\01.udemy\03.vinoth_selvaraj\reactive-redis-masterclass (feature/section-6)
$ docker compose -f ./docker/compose.yml up -d                                                  
[+] Running 3/3                                                                                 
 ‚úî Volume "postgres-data"  Created                                                              
 ‚úî Container c-postgres    Started                                                              
 ‚úî Container c-redis       Running                                                                                                                                                                                                                                                                  0.0s  ‚úî Container c-postgres    Started                                                                                                                                                                                                       0.3s  ‚úî Container c-redis       Running
````

Al listar nuevamente los contenedores, podremos verificar que el contenedor de `PostgreSQL` ya est√° en ejecuci√≥n, junto
con el contenedor de `Redis` que hab√≠amos creado previamente al inicio del curso.

````bash
$ docker container ls -a
CONTAINER ID   IMAGE                                 COMMAND                  CREATED              STATUS                        PORTS                                         NAMES
6728aae1932d   postgres:17-alpine                    "docker-entrypoint.s‚Ä¶"   About a minute ago   Up About a minute             0.0.0.0:5433->5432/tcp, [::]:5433->5432/tcp   c-postgres
34818d6d187b   redis:8.0.3-alpine                    "docker-entrypoint.s‚Ä¶"   2 weeks ago          Up 24 minutes                 0.0.0.0:6379->6379/tcp, [::]:6379->6379/tcp   c-redis 
````

## ‚öôÔ∏è Agregando configuraci√≥n de conexi√≥n a PostgreSQL

Para que nuestra aplicaci√≥n pueda conectarse a la base de datos que levantamos con Docker, debemos agregar las
siguientes configuraciones en el archivo `application.yml`:

````yml
server:
  port: 8080
  error:
    include-message: always

spring:
  application:
    name: redis-performance
  r2dbc:
    url: r2dbc:postgresql://localhost:5433/db_redis_performance
    username: postgres
    password: magadiflo

logging:
  level:
    io.r2dbc.postgresql.QUERY: debug
    io.r2dbc.postgresql.PARAM: debug
````

üìù Explicaci√≥n de los bloques:

- `server.port`: Puerto en el que se ejecutar√° la aplicaci√≥n Spring Boot.
- `spring.r2dbc.url`: URL de conexi√≥n R2DBC hacia PostgreSQL, usando el puerto expuesto por Docker (5433).
- `spring.r2dbc.username/password`: Credenciales definidas en el `compose.yml`.
- `logging.level`: Activamos logs de consultas y par√°metros enviados por el cliente R2DBC para facilitar el seguimiento
  durante el desarrollo y pruebas.

‚úÖ Con esta configuraci√≥n, la aplicaci√≥n ya puede establecer conexi√≥n reactiva con `PostgreSQL` mediante `R2DBC`.

## Configuraci√≥n de datos iniciales (Data Setup Service)

### 1. Script SQL de esquema de base de datos

Creamos el siguiente script para definir el esquema de la tabla products. Guardamos este archivo en la ubicaci√≥n
`src/main/resources/sql/scheme.sql`.

````sql
DROP TABLE IF EXISTS products;

CREATE TABLE products(
    id INTEGER GENERATED ALWAYS AS IDENTITY,
    description VARCHAR(500),
    price NUMERIC(10,2),
    CONSTRAINT pk_products PRIMARY KEY(id)
);
````

En versiones modernas de `PostgreSQL` (a partir de la `+10`), se recomienda usar la cl√°usula
`GENERATED {ALWAYS|BY DEFAULT} AS IDENTITY` en lugar del tipo `SERIAL` para definir columnas `autoincrementales`.

¬øQu√© significa?

- `INTEGER`: Tipo de dato de la columna, que ser√° num√©rico entero.
- `GENERATED ALWAYS`: Le indica a `PostgreSQL` que los valores de esta columna `ser√°n generados autom√°ticamente` por el
  sistema.
    - Si intentamos insertar manualmente un valor en esta columna, obtendremos un error.
- `AS IDENTITY`: Indica que la columna usar√° una secuencia interna para generar valores √∫nicos, muy similar a lo que
  hac√≠a `SERIAL`, pero de forma m√°s est√°ndar y controlada.

> Al usar `ALWAYS`:
> - PostgreSQL siempre genera el valor autom√°ticamente usando una secuencia.
> - Si intentas insertar un valor manualmente en esa columna, obtendr√°s un error.
>
> Si usamos `BY DEFAULT`, entonces:
> - PostgreSQL usar√° la secuencia autom√°ticamente solo si no se proporciona un valor.
> - Si t√∫ proporcionas manualmente un valor, PostgreSQL lo aceptar√° sin error.

### 2. Configuraci√≥n autom√°tica de base de datos y carga inicial de datos

Creamos una clase de configuraci√≥n que se encargar√° de dos tareas:

1. Ejecutar el script SQL al arrancar la aplicaci√≥n.
2. Poblar la tabla products con 1000 registros de prueba.

````java

@Slf4j
@RequiredArgsConstructor
@Configuration
public class DataSetupConfig {

    @Bean
    public ConnectionFactoryInitializer initializer(ConnectionFactory connectionFactory) {
        ClassPathResource scheme = new ClassPathResource("sql/scheme.sql");
        ResourceDatabasePopulator resourceDatabasePopulator = new ResourceDatabasePopulator(scheme);

        ConnectionFactoryInitializer initializer = new ConnectionFactoryInitializer();
        initializer.setConnectionFactory(connectionFactory);
        initializer.setDatabasePopulator(resourceDatabasePopulator);
        return initializer;
    }

    @Bean
    public CommandLineRunner runner(ProductRepository productRepository) {
        return args -> Flux.range(1, 1000)
                .map(i -> Product.builder()
                        .description("product-" + i)
                        .price(ThreadLocalRandom.current().nextInt(1, 100))
                        .build()
                )
                .collectList()
                .flatMapMany(productRepository::saveAll)
                .then()
                .doFinally(signalType -> log.info("Configuraci√≥n de datos realizada: {}", signalType))
                .subscribe();
    }
}
````

- `ConnectionFactoryInitializer`: Se encarga de ejecutar el script `scheme.sql` al iniciar la aplicaci√≥n, utilizando
  `R2DBC`.
- `CommandLineRunner`: Una vez que la tabla ha sido creada, se insertan 1000 productos con descripciones del tipo
  `product-1`, `product-2`, ..., y precios aleatorios entre 1 y 99.
- `doFinally(...)`: Al finalizar la ejecuci√≥n del flujo, se imprime un log con la se√±al de finalizaci√≥n.

### 3. Comprobando inicializaci√≥n

Una vez ejecutada la aplicaci√≥n, realizamos algunas peticiones para verificar que todo funciona correctamente: la
conexi√≥n a la base de datos, la creaci√≥n autom√°tica de los datos y el correcto funcionamiento de los endpoints.

Hacemos una petici√≥n GET para obtener el producto con ID 10.

````bash
$ curl -v http://localhost:8080/api/v1/products/10 | jq
>
< HTTP/1.1 200 OK
< Content-Type: application/json
< Content-Length: 49
<
{
  "id": 10,
  "description": "product-10",
  "price": 93.0
}
````

La respuesta confirma que el producto fue encontrado correctamente. Recordemos que al iniciar la aplicaci√≥n, se
insertaron 1000 productos de prueba con descripciones `product-1` a `product-1000`.

Ahora actualizamos el producto 10 usando una petici√≥n PUT, cambiando su descripci√≥n y precio.

````bash
$ curl -v -X PUT -H "Content-Type: application/json" -d "{\"description\": \"Monitor LG\", \"price\": 750.50}" http://localhost:8080/api/v1/products/10 | jq
>
< HTTP/1.1 200 OK
< Content-Type: application/json
< Content-Length: 50
<
{
  "id": 10,
  "description": "Monitor LG",
  "price": 750.5
}
````

La respuesta muestra que el producto fue actualizado exitosamente en la base de datos.

## Instalaci√≥n de Apache JMeter

Para realizar pruebas de rendimiento sobre nuestra API, utilizaremos `Apache JMeter`, una herramienta de c√≥digo abierto
muy popular para pruebas de carga.

Puedes descargar la √∫ltima versi√≥n desde el siguiente enlace oficial:
[Download Apache JMeter](https://jmeter.apache.org/download_jmeter.cgi).
Aseg√∫rate de descargar el archivo `binario (.zip)`, no el c√≥digo fuente.

![03.png](assets/section-06/03.png)

Una vez descargado el archivo `.zip`, descompr√≠melo en una ubicaci√≥n de tu preferencia. Por ejemplo.

````bash
C:\jmeter\apache-jmeter-5.6.3 
````

Para ejecutar `JMeter` en `Windows`, dir√≠gete a la carpeta `/bin` y ejecuta el archivo `jmeter.bat`.

````bash
C:\jmeter\apache-jmeter-5.6.3\bin
$ jmeter.bat
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
================================================================================
Don't use GUI mode for load testing !, only for Test creation and Test debugging.
For load testing, use CLI Mode (was NON GUI):
   jmeter -n -t [jmx file] -l [results file] -e -o [Path to web report folder]
& increase Java Heap to meet your test requirements:
   Modify current env variable HEAP="-Xms1g -Xmx1g -XX:MaxMetaspaceSize=256m" in the jmeter batch file
Check : https://jmeter.apache.org/usermanual/best-practices.html
================================================================================
````

Los mensajes en consola simplemente son advertencias y buenas pr√°cticas sugeridas por la herramienta. No afectan la
ejecuci√≥n.

Despu√©s de unos segundos, se abrir√° la interfaz gr√°fica de `JMeter`:

![04.png](assets/section-06/04.png)

## Jmeter - un breve curso intensivo

En el directorio `external/jmeter/product-service.jmx` se encuentra el archivo de prueba que nos proporcion√≥ el tutor.
Una vez que tenemos `JMeter` en funcionamiento, procedemos a abrir dicho archivo desde la interfaz gr√°fica.

![05.png](assets/section-06/05.png)

Al abrirlo, veremos un plan de prueba ya `preconfigurado`. En mi caso, lo √∫nico que modifiqu√© fue el campo `Path`,
actualiz√°ndolo para que coincida con el endpoint que expone mi aplicaci√≥n `WebFlux`.

![06.png](assets/section-06/06.png)

- `${__Random(1,1000,)}`, Esta expresi√≥n es una funci√≥n propia de `JMeter` que genera un n√∫mero aleatorio entre 1
  y 1000. En este caso se est√° utilizando como par√°metro din√°mico en el endpoint, simulando peticiones a distintos
  productos.

Una vez que ejecutamos el plan de prueba, obtendremos resultados como los que se muestran a continuaci√≥n:

![07.png](assets/section-06/07.png)

Hasta aqu√≠, hemos utilizado la interfaz gr√°fica de `JMeter` para configurar y ejecutar nuestras pruebas. Sin embargo,
`no es recomendable usar la GUI de JMeter para ejecutar pruebas de carga reales`, ya que consume muchos recursos
del sistema y puede afectar la precisi√≥n de los resultados.

> ‚úÖ Lo ideal es `usar JMeter en modo consola (CLI)` para ejecutar las pruebas de rendimiento. Esto lo veremos en el
> siguiente apartado.

## üìä Prueba Base (Baseline Test)

En esta secci√≥n realizamos una prueba de rendimiento b√°sica para establecer una l√≠nea base (baseline) de comparaci√≥n,
antes de aplicar caching con Redis. Para ello, ejecutamos una prueba de carga usando `Apache JMeter` en
`modo no gr√°fico` desde la terminal.

````bash
C:\jmeter\apache-jmeter-5.6.3\bin
$ jmeter -n -t D:\programming\spring\01.udemy\03.vinoth_selvaraj\reactive-redis-masterclass\external\jmeter\product-service.jmx -l D:\programming\spring\01.udemy\03.vinoth_selvaraj\reactive-redis-masterclass\external\jmeter\v1.jtl
````

üß© Par√°metros explicados

- Observemos que estamos ejecutando el comando dentro del directorio `/bin`.
- `-n`. Ejecuta `JMeter` en `modo no gr√°fico` (`non-GUI`). Esto es √∫til para ejecutar pruebas desde l√≠nea de comandos
  o scripts automatizados sin necesidad de abrir la interfaz gr√°fica.
- `-t <ruta_del_archivo.jmx>`. Especifica el script de prueba JMeter que se va a ejecutar. En este caso, usamos
  `product-service.jmx`, el cual contiene la configuraci√≥n de los `hilos`, `peticiones` y `validaciones`.
- `-l <ruta_del_archivo.jtl>`. Define el archivo de salida de resultados, con extensi√≥n `.jtl`. Este archivo ser√° creado
  al ejecutar el comando, adem√°s, este archivo almacena los datos brutos generados durante la ejecuci√≥n, que luego
  pueden ser visualizados en la interfaz gr√°fica de JMeter.

### üß™ Resultado de la ejecuci√≥n

Durante la ejecuci√≥n del test, se muestran varias m√©tricas resumen directamente en consola:

````bash
C:\jmeter\apache-jmeter-5.6.3\bin
$ jmeter -n -t D:\programming\spring\01.udemy\03.vinoth_selvaraj\reactive-redis-masterclass\external\jmeter\product-service.jmx -l D:\programming\spring\01.udemy\03.vinoth_selvaraj\reactive-redis-masterclass\external\jmeter\v1.jtl
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
WARN StatusConsoleListener The use of package scanning to locate plugins is deprecated and will be removed in a future release
Creating summariser <summary>
Created the tree successfully using D:\programming\spring\01.udemy\03.vinoth_selvaraj\reactive-redis-masterclass\external\jmeter\product-service.jmx
Starting standalone test @ 2025 Aug 8 12:29:22 PET (1754674162859)
Waiting for possible Shutdown/StopTestNow/HeapDump/ThreadDump message on port 4445
summary +   7650 in 00:00:07 = 1113.2/s Avg:    19 Min:     3 Max:    74 Err:     0 (0.00%) Active: 46 Started: 46 Finished: 0
summary +  49937 in 00:00:30 = 1664.6/s Avg:    82 Min:    23 Max:   231 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary =  57587 in 00:00:37 = 1561.8/s Avg:    74 Min:     3 Max:   231 Err:     0 (0.00%)
summary +  56951 in 00:00:30 = 1898.4/s Avg:   104 Min:    81 Max:   307 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 114538 in 00:01:07 = 1712.8/s Avg:    89 Min:     3 Max:   307 Err:     0 (0.00%)
summary +  56774 in 00:00:30 = 1892.5/s Avg:   104 Min:    78 Max:   238 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 171312 in 00:01:37 = 1768.4/s Avg:    94 Min:     3 Max:   307 Err:     0 (0.00%)
summary +  53875 in 00:00:30 = 1795.8/s Avg:   110 Min:    82 Max:   307 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 225187 in 00:02:07 = 1774.9/s Avg:    98 Min:     3 Max:   307 Err:     0 (0.00%)
summary +  47809 in 00:00:30 = 1593.6/s Avg:   124 Min:    83 Max:   297 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 272996 in 00:02:37 = 1740.2/s Avg:   102 Min:     3 Max:   307 Err:     0 (0.00%)
summary +  46867 in 00:00:30 = 1562.3/s Avg:   127 Min:    84 Max:   328 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 319863 in 00:03:07 = 1711.7/s Avg:   106 Min:     3 Max:   328 Err:     0 (0.00%)
summary +  40298 in 00:00:30 = 1343.3/s Avg:   148 Min:    88 Max:   440 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 360161 in 00:03:37 = 1660.7/s Avg:   111 Min:     3 Max:   440 Err:     0 (0.00%)
summary +  48175 in 00:00:30 = 1605.8/s Avg:   123 Min:    83 Max:   262 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 408336 in 00:04:07 = 1654.0/s Avg:   112 Min:     3 Max:   440 Err:     0 (0.00%)
summary +  51980 in 00:00:30 = 1732.6/s Avg:   106 Min:    16 Max:   849 Err:     0 (0.00%) Active: 200 Started: 200 Finished: 0
summary = 460316 in 00:04:37 = 1662.6/s Avg:   112 Min:     3 Max:   849 Err:     0 (0.00%)
summary +  41024 in 00:00:23 = 1763.2/s Avg:   112 Min:    84 Max:   327 Err:     0 (0.00%) Active: 0 Started: 200 Finished: 200
summary = 501340 in 00:05:00 = 1670.3/s Avg:   112 Min:     3 Max:   849 Err:     0 (0.00%)
Tidying up ...    @ 2025 Aug 8 12:34:23 PET (1754674463269)
... end of run
````

üìå Interpretaci√≥n:

- Solicitudes totales procesadas: 501,340
- Duraci√≥n de la prueba: 5 minutos
- Throughput promedio: 1670.3 solicitudes por segundo
- Tiempo de respuesta promedio: 112ms
- Errores: 0

### üì∑ Visualizaci√≥n en la UI de JMeter

Una vez finalizada la ejecuci√≥n, podemos abrir el archivo `.jtl` con la interfaz gr√°fica de JMeter y visualizar los
resultados de forma m√°s amigable.

![08.png](assets/section-06/08.png)

En la columna `Throughput (rendimiento)`, se observa claramente que nuestra aplicaci√≥n fue capaz de manejar:

> `‚âà 1671.2 solicitudes por segundo` de manera estable.

![09.png](assets/section-06/09.png)

### üìä Distribuci√≥n de peticiones

En la misma interfaz, tambi√©n se puede observar c√≥mo se distribuyeron los diferentes tipos de solicitudes durante la
prueba:

- GET: 459,128 solicitudes (‚âà90%)
- PUT: 42,212 solicitudes (‚âà10%)

Esto refleja el comportamiento esperado, ya que las operaciones de lectura (GET) son m√°s frecuentes que las de
escritura (PUT) en la mayor√≠a de escenarios de aplicaciones reales.

üìå Conclusi√≥n
> Este test de carga inicial nos permite obtener un punto de referencia sobre el rendimiento del servicio sin ning√∫n
> tipo de caching aplicado. En las siguientes secciones, al integrar Redis como capa de cach√©, podremos comparar estos
> resultados y medir las mejoras de rendimiento obtenidas.
